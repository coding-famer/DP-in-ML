{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fi9RkJQAwxYh",
        "outputId": "a61724a4-28b8-40e2-bdae-ffcede92e9ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Qe2g585UwxYj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Sa8tULHVwxYl",
        "outputId": "6d6c99bd-b2b8-47bf-ec89-2106cd5ba102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Aho-UC-EwxYn",
        "outputId": "f70ccfc3-8a68-42d6-bf16-3c6f5a10d9c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 20 03:16:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    32W /  70W |   5880MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCJfHk7AwxYo"
      },
      "source": [
        "# 超参数设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "W830m3MzwxYp"
      },
      "outputs": [],
      "source": [
        "EPOCH = 10 # 遍历数据集次数\n",
        "BATCH_SIZE = 512  # 批处理尺寸(batch_size)\n",
        "LR = 0.1  # 学习率\n",
        "MAX_GRAD_NORM = 1.2\n",
        "EPSILON = 2\n",
        "DELTA = 1e-4\n",
        "MAX_PHYSICAL_BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqKzBugwxYq"
      },
      "source": [
        "# 获取数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lJo6SLPPwxYr"
      },
      "outputs": [],
      "source": [
        "transform = transforms.ToTensor()\n",
        "trainset = torchvision.datasets.MNIST(root='./dataset',train=True,download=True,transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./dataset',train=False,download=True,transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjMwoWN7wxYt"
      },
      "source": [
        "# 定义网络"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ecZtqUEcwxYu"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, width_mult=1):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential( # 输入1*28*28\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1), # 32*28*28\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 32*14*14\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 64*14*14\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 64*7*7\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 128*7*7\n",
        "            )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 256*7*7\n",
        "            )\n",
        " \n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # 256*7*7\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 256*3*3\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        self.fc1 = nn.Linear(256*3*3, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = x.view(-1, 256*3*3)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgAtvTqwxYv"
      },
      "source": [
        "# 定义网络损失函数优化器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bntro8LzwxYw"
      },
      "source": [
        "该部分尝试自己改写梯度下降，但仿佛会让梯度爆炸，暂时先不用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "gKw0EwA7wxYx"
      },
      "outputs": [],
      "source": [
        "# epsilon = 2\n",
        "\n",
        "# # This analysis has a total privacy cost of epsilon = 1, even though we release many results!\n",
        "# f = lambda x: x + np.random.laplace(loc=0, scale=1/epsilon)\n",
        "\n",
        "# def mysgd(params, lr, batch_size):  \n",
        "#     \"\"\"小批量随机梯度下降\"\"\"\n",
        "#     # print(params)\n",
        "#     with torch.no_grad():\n",
        "#         for param in params:\n",
        "#             # print(param)\n",
        "#             # param -= (lr * param.grad / batch_size).apply(f)\n",
        "#             # param -= (lr * (param.grad+ torch.tensor(np.random.laplace(loc=0, scale=1/epsilon))) ) \n",
        "#             param -= (lr * param.grad) + torch.tensor(np.random.laplace(loc=0, scale=5/epsilon))\n",
        "\n",
        "#             # param -= lr * param.grad / batch_size\n",
        "#             param.grad.zero_()\n",
        "#             # print(param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "USsdwtv5wxYy",
        "outputId": "96a9ee58-d5e6-4c8b-d121-53bf74383cfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "net = AlexNet()\n",
        "from opacus.validators import ModuleValidator\n",
        "\n",
        "errors = ModuleValidator.validate(net, strict=False)\n",
        "errors[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = ModuleValidator.fix(net)\n",
        "ModuleValidator.validate(net, strict=False)\n",
        "net = net.to(device)\n"
      ],
      "metadata": {
        "id": "aEj8AMdAyKD9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，通常用于多分类问题上\n",
        "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)"
      ],
      "metadata": {
        "id": "O3bJFyn82_8l"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "KoaV_cc3wxYy",
        "outputId": "78e16e07-4e79-445a-fe9c-ccd61a088c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:115: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
            "/usr/local/lib/python3.7/dist-packages/opacus/accountants/analysis/rdp.py:333: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  f\"Optimal order is the {extreme} alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sigma=0.909423828125 and C=1.2\n"
          ]
        }
      ],
      "source": [
        "privacy_engine = PrivacyEngine()\n",
        "\n",
        "net, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "    module=net,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=trainloader,\n",
        "    epochs=EPOCH,\n",
        "    target_epsilon=EPSILON,\n",
        "    target_delta=DELTA,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        ")\n",
        "\n",
        "print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsbjGIawxYz"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pd2EIhuuwxYz"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        " \n",
        "    for epoch in range(EPOCH):\n",
        "        sum_loss = 0.0\n",
        "        net.train()\n",
        "        with BatchMemoryManager(\n",
        "            data_loader=trainloader, \n",
        "            max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
        "            optimizer=optimizer\n",
        "        ) as memory_safe_data_loader:\n",
        "            # 数据读取\n",
        "            for i, data in enumerate(memory_safe_data_loader):\n",
        "                # 梯度清零\n",
        "                optimizer.zero_grad() \n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "   \n",
        "                # forward + backward\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                # mysgd(net.parameters(), lr=LR, batch_size=BATCH_SIZE)\n",
        "    \n",
        "                # 每训练100个batch打印一次平均loss\n",
        "                sum_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    print('[%d, %d] loss: %.03f'\n",
        "                        % (epoch + 1, i + 1, sum_loss / 100))\n",
        "                    sum_loss = 0.0\n",
        "            # 每跑完一次epoch测试一下准确率\n",
        "            net.eval()\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for data in testloader:\n",
        "                    images, labels = data\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = net(images)\n",
        "                    # 取得分最高的那个类\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum()\n",
        "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
        "                print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, (100 * correct / total)),f\"(ε = {epsilon:.2f}, δ = {DELTA})\")\n",
        "            # 保存模型参数\n",
        "            # torch.save(net.state_dict(), './params.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "2QEsXAhkwxY0",
        "outputId": "abf38fa6-dfa8-47e1-d946-9613a971a7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 100] loss: 2.295\n",
            "[1, 200] loss: 2.035\n",
            "[1, 300] loss: 1.065\n",
            "[1, 400] loss: 0.942\n",
            "第1个epoch的识别准确率为：81% (ε = 1.11, δ = 0.0001)\n",
            "[2, 100] loss: 0.838\n",
            "[2, 200] loss: 0.734\n",
            "[2, 300] loss: 0.686\n",
            "[2, 400] loss: 0.666\n",
            "第2个epoch的识别准确率为：84% (ε = 1.24, δ = 0.0001)\n",
            "[3, 100] loss: 0.831\n",
            "[3, 200] loss: 0.727\n",
            "[3, 300] loss: 0.695\n",
            "[3, 400] loss: 0.606\n",
            "第3个epoch的识别准确率为：88% (ε = 1.35, δ = 0.0001)\n",
            "[4, 100] loss: 0.810\n",
            "[4, 200] loss: 0.747\n",
            "[4, 300] loss: 0.862\n",
            "[4, 400] loss: 0.954\n",
            "第4个epoch的识别准确率为：90% (ε = 1.46, δ = 0.0001)\n",
            "[5, 100] loss: 1.077\n",
            "[5, 200] loss: 1.543\n",
            "[5, 300] loss: 1.143\n",
            "[5, 400] loss: 1.304\n",
            "第5个epoch的识别准确率为：88% (ε = 1.55, δ = 0.0001)\n",
            "[6, 100] loss: 1.270\n",
            "[6, 200] loss: 1.341\n",
            "[6, 300] loss: 1.530\n",
            "[6, 400] loss: 1.753\n",
            "第6个epoch的识别准确率为：90% (ε = 1.65, δ = 0.0001)\n",
            "[7, 100] loss: 1.733\n",
            "[7, 200] loss: 1.825\n",
            "[7, 300] loss: 2.168\n",
            "[7, 400] loss: 2.425\n",
            "第7个epoch的识别准确率为：89% (ε = 1.74, δ = 0.0001)\n",
            "[8, 100] loss: 2.326\n",
            "[8, 200] loss: 2.674\n",
            "[8, 300] loss: 2.804\n",
            "[8, 400] loss: 3.132\n",
            "第8个epoch的识别准确率为：86% (ε = 1.83, δ = 0.0001)\n",
            "[9, 100] loss: 3.187\n",
            "[9, 200] loss: 3.078\n",
            "[9, 300] loss: 3.535\n",
            "[9, 400] loss: 3.219\n",
            "第9个epoch的识别准确率为：83% (ε = 1.91, δ = 0.0001)\n",
            "[10, 100] loss: 4.395\n",
            "[10, 200] loss: 4.581\n",
            "[10, 300] loss: 4.501\n",
            "[10, 400] loss: 4.483\n",
            "第10个epoch的识别准确率为：86% (ε = 1.99, δ = 0.0001)\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abZi5GPwwxY1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "73e1d25d57e14df6cec64c283e0dd23faae1c4fc370d549e379c51e4d2bab0ac"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "dp-alexnet-minst.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}