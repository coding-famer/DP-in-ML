{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10 # 遍历数据集次数\n",
    "BATCH_SIZE = 64  # 批处理尺寸(batch_size)\n",
    "LR = 0.01  # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root='./dataset',train=True,download=False,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./dataset',train=False,download=False,transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE,shuffle=False,num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, width_mult=1):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential( # 输入1*28*28\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1), # 32*28*28\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 32*14*14\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 64*14*14\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 64*7*7\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 128*7*7\n",
    "            )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 256*7*7\n",
    "            )\n",
    " \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # 256*7*7\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), # 256*3*3\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(256*3*3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(-1, 256*3*3)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络损失函数优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 2\n",
    "\n",
    "# This analysis has a total privacy cost of epsilon = 1, even though we release many results!\n",
    "f = lambda x: x + np.random.laplace(loc=0, scale=1/epsilon)\n",
    "\n",
    "def mysgd(params, lr, batch_size):  \n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    # print(params)\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            # print(param)\n",
    "            # param -= (lr * param.grad / batch_size).apply(f)\n",
    "            # param -= (lr * (param.grad+ torch.tensor(np.random.laplace(loc=0, scale=1/epsilon))) ) \n",
    "            param -= (lr * param.grad) + torch.tensor(np.random.laplace(loc=0, scale=5/epsilon))\n",
    "\n",
    "            # param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "            # print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，通常用于多分类问题上\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    " \n",
    "    for epoch in range(EPOCH):\n",
    "        sum_loss = 0.0\n",
    "        # 数据读取\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "            # 梯度清零\n",
    "            # optimizer.zero_grad()\n",
    " \n",
    "            # forward + backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # optimizer.step()\n",
    "            mysgd(net.parameters(), lr=LR, batch_size=BATCH_SIZE)\n",
    " \n",
    "            # 每训练100个batch打印一次平均loss\n",
    "            sum_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %d] loss: %.03f'\n",
    "                      % (epoch + 1, i + 1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "        # 每跑完一次epoch测试一下准确率\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                # 取得分最高的那个类\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, (100 * correct / total)))\n",
    "        # 保存模型参数\n",
    "        # torch.save(net.state_dict(), './params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.293\n",
      "[1, 200] loss: 1.483\n",
      "[1, 300] loss: 0.297\n",
      "[1, 400] loss: 0.179\n",
      "[1, 500] loss: 0.137\n",
      "[1, 600] loss: 0.112\n",
      "第1个epoch的识别准确率为：97%\n",
      "[2, 100] loss: 0.087\n",
      "[2, 200] loss: 0.078\n",
      "[2, 300] loss: 0.084\n",
      "[2, 400] loss: 0.066\n",
      "[2, 500] loss: 0.071\n",
      "[2, 600] loss: 0.063\n",
      "第2个epoch的识别准确率为：98%\n",
      "[3, 100] loss: 0.057\n",
      "[3, 200] loss: 0.050\n",
      "[3, 300] loss: 0.054\n",
      "[3, 400] loss: 0.046\n",
      "[3, 500] loss: 0.053\n",
      "[3, 600] loss: 0.048\n",
      "第3个epoch的识别准确率为：98%\n",
      "[4, 100] loss: 0.043\n",
      "[4, 200] loss: 0.043\n",
      "[4, 300] loss: 0.038\n",
      "[4, 400] loss: 0.034\n",
      "[4, 500] loss: 0.036\n",
      "[4, 600] loss: 0.038\n",
      "第4个epoch的识别准确率为：98%\n",
      "[5, 100] loss: 0.033\n",
      "[5, 200] loss: 0.030\n",
      "[5, 300] loss: 0.027\n",
      "[5, 400] loss: 0.035\n",
      "[5, 500] loss: 0.026\n",
      "[5, 600] loss: 0.036\n",
      "第5个epoch的识别准确率为：99%\n",
      "[6, 100] loss: 0.029\n",
      "[6, 200] loss: 0.024\n",
      "[6, 300] loss: 0.031\n",
      "[6, 400] loss: 0.023\n",
      "[6, 500] loss: 0.025\n",
      "[6, 600] loss: 0.025\n",
      "第6个epoch的识别准确率为：98%\n",
      "[7, 100] loss: 0.021\n",
      "[7, 200] loss: 0.018\n",
      "[7, 300] loss: 0.023\n",
      "[7, 400] loss: 0.022\n",
      "[7, 500] loss: 0.027\n",
      "[7, 600] loss: 0.021\n",
      "第7个epoch的识别准确率为：99%\n",
      "[8, 100] loss: 0.012\n",
      "[8, 200] loss: 0.022\n",
      "[8, 300] loss: 0.025\n",
      "[8, 400] loss: 0.022\n",
      "[8, 500] loss: 0.017\n",
      "[8, 600] loss: 0.017\n",
      "第8个epoch的识别准确率为：99%\n",
      "[9, 100] loss: 0.013\n",
      "[9, 200] loss: 0.016\n",
      "[9, 300] loss: 0.012\n",
      "[9, 400] loss: 0.014\n",
      "[9, 500] loss: 0.017\n",
      "[9, 600] loss: 0.014\n",
      "第9个epoch的识别准确率为：99%\n",
      "[10, 100] loss: 0.011\n",
      "[10, 200] loss: 0.013\n",
      "[10, 300] loss: 0.015\n",
      "[10, 400] loss: 0.017\n",
      "[10, 500] loss: 0.014\n",
      "[10, 600] loss: 0.019\n",
      "第10个epoch的识别准确率为：98%\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73e1d25d57e14df6cec64c283e0dd23faae1c4fc370d549e379c51e4d2bab0ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
